{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "import copy\n",
    "import numpy as np\n",
    "import scipy\n",
    "import torch_geometric\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.utils as utils\n",
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim=None, sigma=False, bias=False):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear_1 = nn.Linear(input_dim, hidden_dim, bias=bias)\n",
    "        if output_dim != None:\n",
    "            self.linear_2 = nn.Linear(hidden_dim, output_dim, bias=bias)\n",
    "        self.sigma = sigma\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        if self.sigma and self.output_dim != None:\n",
    "            x = F.relu(x)\n",
    "            x = self.linear_2(x)\n",
    "        return (x)\n",
    "    \n",
    "\n",
    "    \n",
    "class Node:\n",
    "    \n",
    "    def __init__(self, x, y, mlp, learning_rate, node_id):\n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y.view(1)\n",
    "        self.mlp = mlp\n",
    "        self.node_id = node_id\n",
    "        self.learning_rate = learning_rate\n",
    "        self.optimizer = torch.optim.SGD(self.mlp.parameters(), lr=self.learning_rate)  \n",
    "        \n",
    "    def receive_params(self, parameters):\n",
    "        \n",
    "        # parameters: a dict of parameters: {\"linear_1.weight\": tensor,......}\n",
    "        with torch.no_grad():\n",
    "            for name, param in self.mlp.named_parameters():\n",
    "                param.copy_(parameters[name])\n",
    "                \n",
    "        \n",
    "    def upload_params(self):\n",
    "        \n",
    "        # return a dict of parameters: {\"linear_1,weight\":\" tensor,......,}\n",
    "        return mlp.state_dict()\n",
    "    \n",
    "    # Use this funtion only at the beginning of each communication\n",
    "    def upload_h(self): \n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        h = self.mlp(self.x)\n",
    "        return h\n",
    "    \n",
    "    def receive_and_update(self, Abar_v, h_u, h_v, E):\n",
    "        \n",
    "        \n",
    "        # h_u is the aggregated information of the neighboors of node v, it is constant\n",
    "        # Abar_v is the corresponding constant for h_v and it is constant\n",
    "        \n",
    "        Z_v = (Abar_v*h_v + h_u)\n",
    "        yhat_v = F.log_softmax(Z_v, dim=0)\n",
    "        loss = F.nll_loss(yhat_v.view(1,-1), self.y)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        for e in range(E-1):\n",
    "            self.optimizer.zero_grad()\n",
    "            h_v = self.mlp(self.x)\n",
    "            Z_v = (Abar_v*h_v + h_u)\n",
    "            yhat_v = F.log_softmax(Z_v, dim=0)\n",
    "            loss = F.nll_loss(yhat_v.view(1,-1), self.y)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "class Central_Server:\n",
    "    \n",
    "    def __init__(self, edge_index, node_list, A, K, alpha=0.95):\n",
    "        \n",
    "        self.edge_index = edge_index\n",
    "        self.node_list = node_list\n",
    "        self.A = A\n",
    "        self.alpha = alpha\n",
    "        self.K = K\n",
    "        self.Abar = None\n",
    "        self.central_params = None\n",
    "        self.num_nodes = len(node_list)\n",
    "        \n",
    "    def testing_mlp(self, input_dim, hidden_dim, output_dim=None, sigma=False):\n",
    "        self.mlp = MLP(input_dim, hidden_dim, output_dim, sigma)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def receive_h(self):\n",
    "        \n",
    "        H = []\n",
    "        for v in self.node_list:\n",
    "            h_v = v.upload_h()\n",
    "            with torch.no_grad():\n",
    "                H.append(h_v)\n",
    "        return H\n",
    "    \n",
    "    def compute_Abar(self):\n",
    "        \n",
    "        N = self.A.shape[0]\n",
    "        A_bar = torch.zeros((N,N))\n",
    "        A_i = torch.diag(torch.ones(N))\n",
    "        alpha_i = 1\n",
    "        for i in range(0, self.K+1):\n",
    "            A_bar = A_bar + alpha_i*A_i\n",
    "            alpha_i = alpha_i * self.alpha\n",
    "            A_i = torch.matmul(A_i, self.A)\n",
    "        A_bar = (1-self.alpha)*A_bar\n",
    "        self.Abar = A_bar\n",
    "    \n",
    "    def init_params(self):\n",
    "        \n",
    "        \n",
    "        params = copy.deepcopy(self.node_list[0].mlp.state_dict())\n",
    "        self.cparam_names = list(params.keys())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for param_name in params.keys():\n",
    "                nn.init.normal_(params[param_name])\n",
    "        self.central_params = params\n",
    "        print (self.central_params)\n",
    "        \n",
    "        \n",
    "            \n",
    "    def one_communication(self, E):\n",
    "        \n",
    "        # Calculate the A_bar matrix, if it is not calculated already.\n",
    "        if (self.Abar == None):\n",
    "            self.compute_Abar()\n",
    "            \n",
    "        # If this is the first time, initilalize the central parameters.\n",
    "        if (self.central_params == None):\n",
    "            self.init_params()\n",
    "            \n",
    "        # Broadcasting the current central parameters to all nodes:\n",
    "        for v in self.node_list:\n",
    "            v.receive_params(self.central_params)\n",
    "            \n",
    "        # forwardn through the MLP layers for each node\n",
    "        H = self.receive_h()\n",
    "        \n",
    "        # Power iteration\n",
    "        H_copy = torch.stack(H).clone().detach()\n",
    "        Z_K = torch.matmul(self.Abar, H_copy)\n",
    "        \n",
    "        # Shape of H\n",
    "        num_nodes, num_classes = H_copy.shape\n",
    "        \n",
    "        # Calculate the needed information for each node to get the yhat\n",
    "        for i in range(num_nodes):\n",
    "            with torch.no_grad():\n",
    "                h_u = Z_K[i,:] - H_copy[i,:]*self.Abar[i,i]\n",
    "            # Local update\n",
    "            self.node_list[i].receive_and_update(self.Abar[i,i], h_u, H[i], E)\n",
    "            \n",
    "        # Collect the updated local parameters and aggregate\n",
    "        with torch.no_grad():\n",
    "            for pname in self.cparam_names:\n",
    "                p = self.node_list[0].mlp.state_dict()[pname]\n",
    "                for i in range(1, self.num_nodes):\n",
    "                    p = p + self.node_list[i].mlp.state_dict()[pname]\n",
    "                p = p/self.num_nodes\n",
    "                self.central_params[pname] = p\n",
    "            \n",
    "            \n",
    "    def training(self, T, E):\n",
    "        \n",
    "        for t in range(T):\n",
    "            self.one_communication(E)\n",
    "            print (\"Communication:\", t+1)\n",
    "            \n",
    "    def training_accuracy(self, graph_data, params):\n",
    "        X = graph_data.x\n",
    "        Y = graph_data.y\n",
    "        self.mlp.load_state_dict(params)\n",
    "        with torch.no_grad():\n",
    "                H = self.mlp(X)\n",
    "                Z_K = torch.matmul(self.Abar, H)\n",
    "                preds = torch.max(Z_K, dim=1)[1]\n",
    "                counts = (preds == Y).sum()\n",
    "        print (counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_network(data, A, num_classes, hidden_dim, learning_rate, K,\n",
    "                       output_dim=None, sigma=False):\n",
    "    \n",
    "    num_nodes, input_dim = data.x.shape\n",
    "    node_list = []\n",
    "    \n",
    "    for v in range(num_nodes):\n",
    "        \n",
    "        if (output_dim != None and sigma == True):\n",
    "            mlp = MLP(input_dim, hidden_dim, output_dim, sigma)\n",
    "            \n",
    "        else:\n",
    "            mlp = MLP(input_dim, hidden_dim)\n",
    "            \n",
    "        node_v = Node(data.x[v,:], data.y[v], mlp, learning_rate, v)\n",
    "        node_list.append(node_v)\n",
    "    \n",
    "    network = Central_Server(data.edge_index, node_list, A, K)\n",
    "    \n",
    "    network.testing_mlp(input_dim, hidden_dim, output_dim, sigma)\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear_1.weight', tensor([[ 0.2780,  0.4091, -0.8773,  ..., -0.0978,  1.0145, -0.5874],\n",
      "        [ 0.5348,  0.5002, -0.6751,  ..., -0.2304,  1.0212,  0.6547],\n",
      "        [-1.9875, -0.7744,  2.8199,  ..., -0.5654,  1.0590,  0.6054],\n",
      "        ...,\n",
      "        [-0.3207,  1.3769,  0.4110,  ...,  1.2728,  0.2249, -0.9476],\n",
      "        [ 0.4499,  0.9240, -0.6139,  ...,  0.4759,  1.2984,  0.9053],\n",
      "        [ 0.7185, -0.7133,  0.0995,  ...,  0.7702, -0.0281,  1.3712]]))])\n",
      "Communication: 1\n",
      "Communication: 2\n",
      "Communication: 3\n",
      "Communication: 4\n",
      "Communication: 5\n",
      "Communication: 6\n",
      "Communication: 7\n",
      "Communication: 8\n",
      "Communication: 9\n",
      "Communication: 10\n",
      "Communication: 11\n",
      "Communication: 12\n",
      "Communication: 13\n",
      "Communication: 14\n",
      "Communication: 15\n",
      "Communication: 16\n",
      "Communication: 17\n",
      "Communication: 18\n",
      "Communication: 19\n",
      "Communication: 20\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "data.edge_index = utils.remove_self_loops(data.edge_index)[0]\n",
    "data.edge_index = utils.add_remaining_self_loops(data.edge_index)[0]\n",
    "G = utils.to_networkx(data, to_undirected=True)\n",
    "A = torch.tensor(nx.linalg.graphmatrix.adjacency_matrix(G).todense()).type(torch.FloatTensor)\n",
    "D = nx.linalg.graphmatrix.adjacency_matrix(G).todense() + nx.linalg.laplacianmatrix.laplacian_matrix(G).todense()\n",
    "Dhalf = scipy.linalg.sqrtm(D)\n",
    "Dnhalf = torch.tensor(scipy.linalg.inv(Dhalf)).type(torch.FloatTensor)\n",
    "A = torch.matmul(torch.matmul(Dnhalf, A), Dnhalf)\n",
    "server = init_network(data, A, 7, 7, 0.1, 20)\n",
    "server.training(20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear_1.weight',\n",
       "              tensor([[ 0.2777,  0.4087, -0.8773,  ..., -0.0976,  1.0144, -0.5874],\n",
       "                      [ 0.5348,  0.5002, -0.6750,  ..., -0.2304,  1.0213,  0.6547],\n",
       "                      [-1.9874, -0.7744,  2.8198,  ..., -0.5654,  1.0588,  0.6053],\n",
       "                      ...,\n",
       "                      [-0.3207,  1.3769,  0.4106,  ...,  1.2727,  0.2244, -0.9475],\n",
       "                      [ 0.4499,  0.9241, -0.6139,  ...,  0.4759,  1.2984,  0.9053],\n",
       "                      [ 0.7185, -0.7134,  0.0986,  ...,  0.7701, -0.0283,  1.3711]]))])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server.central_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
