{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import copy\n",
    "import numpy as np\n",
    "import scipy\n",
    "import torch_geometric\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.utils as utils\n",
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim=None, sigma=False, bias=False):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear_1 = nn.Linear(input_dim, hidden_dim, bias=bias)\n",
    "        if output_dim != None:\n",
    "            self.linear_2 = nn.Linear(hidden_dim, output_dim, bias=bias)\n",
    "        self.sigma = sigma\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        if self.sigma and self.output_dim != None:\n",
    "            x = F.relu(x)\n",
    "            x = self.linear_2(x)\n",
    "        return (x)\n",
    "    \n",
    "\n",
    "    \n",
    "class Node:\n",
    "    \n",
    "    def __init__(self, x, y, mlp, learning_rate, node_id):\n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y.view(1)\n",
    "        self.mlp = mlp\n",
    "        self.node_id = node_id\n",
    "        self.learning_rate = learning_rate\n",
    "        self.optimizer = torch.optim.SGD(self.mlp.parameters(), lr=self.learning_rate)\n",
    "        \n",
    "    def receive_params(self, parameters):\n",
    "        \n",
    "        # parameters: a dict of parameters: {\"linear_1.weight\": tensor,......}\n",
    "        with torch.no_grad():\n",
    "            for name, param in self.mlp.named_parameters():\n",
    "                param.copy_(parameters[name])\n",
    "                \n",
    "        \n",
    "    def upload_params(self):\n",
    "        \n",
    "        # return a dict of parameters: {\"linear_1,weight\":\" tensor,......,}\n",
    "        return mlp.state_dict()\n",
    "    \n",
    "    # Use this funtion only at the beginning of each communication\n",
    "    def upload_h(self): \n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        h = self.mlp(self.x)\n",
    "        return h\n",
    "    \n",
    "    def receive_and_update(self, Abar_v, h_u, h_v, E):\n",
    "        \n",
    "        \n",
    "        # h_u is the aggregated information of the neighboors of node v, it is constant\n",
    "        # Abar_v is the corresponding constant for h_v and it is constant\n",
    "        \n",
    "        Z_v = Abar_v*h_v + h_u\n",
    "        yhat_v = F.log_softmax(Z_v, dim=0)\n",
    "        loss = F.nll_loss(yhat_v.view(1,-1), self.y)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        for e in range(E-1):\n",
    "            self.optimizer.zero_grad()\n",
    "            h_v = self.mlp(self.x)\n",
    "            Z_v = (Abar_v*h_v + h_u)\n",
    "            yhat_v = F.log_softmax(Z_v, dim=0)\n",
    "            loss = F.nll_loss(yhat_v.view(1,-1), self.y)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "class Central_Server:\n",
    "    \n",
    "    def __init__(self, edge_index, node_list, A, K, alpha=0.95):\n",
    "        \n",
    "        self.edge_index = edge_index\n",
    "        self.node_list = node_list\n",
    "        self.A = A\n",
    "        self.alpha = alpha\n",
    "        self.K = K\n",
    "        self.Abar = None\n",
    "        self.central_params = None\n",
    "        self.num_nodes = len(node_list)\n",
    "        \n",
    "    def testing_mlp(self, input_dim, hidden_dim, output_dim=None, sigma=False):\n",
    "        self.mlp = MLP(input_dim, hidden_dim, output_dim, sigma)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def receive_h(self):\n",
    "        \n",
    "        H = []\n",
    "        for v in self.node_list:\n",
    "            h_v = v.upload_h()\n",
    "            H.append(h_v)\n",
    "        return H\n",
    "    \n",
    "    def compute_Abar(self):\n",
    "        \n",
    "        N = self.num_nodes\n",
    "        A_bar = torch.zeros((N,N))\n",
    "        A_i = torch.diag(torch.ones(N))\n",
    "        alpha_i = 1\n",
    "        for i in range(0, self.K+1):\n",
    "            A_bar = A_bar + alpha_i*A_i\n",
    "            alpha_i = alpha_i * self.alpha\n",
    "            A_i = torch.matmul(A_i, self.A)\n",
    "        A_bar = (1-self.alpha)*A_bar\n",
    "        self.Abar = A_bar\n",
    "    \n",
    "    def init_params(self):\n",
    "        \n",
    "        \n",
    "        params = copy.deepcopy(self.node_list[0].mlp.state_dict())\n",
    "        self.cparam_names = list(params.keys())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for param_name in params.keys():\n",
    "                nn.init.normal_(params[param_name])\n",
    "        self.central_params = params\n",
    "        \n",
    "        \n",
    "            \n",
    "    def one_communication(self, E):\n",
    "        \n",
    "        # Calculate the A_bar matrix, if it is not calculated already.\n",
    "        if (self.Abar == None):\n",
    "            self.compute_Abar()\n",
    "            \n",
    "        # If this is the first time, initilalize the central parameters.\n",
    "        if (self.central_params == None):\n",
    "            self.init_params()\n",
    "            \n",
    "        # Broadcasting the current central parameters to all nodes:\n",
    "        for v in self.node_list:\n",
    "            v.receive_params(self.central_params)\n",
    "            \n",
    "        # forwardn through the MLP layers for each node\n",
    "        H = self.receive_h()\n",
    "        \n",
    "        # Power iteration\n",
    "        H_copy = torch.stack(H).clone().detach()\n",
    "        Z_K = torch.matmul(self.Abar, H_copy)\n",
    "        \n",
    "        # Shape of H\n",
    "        num_nodes, num_classes = H_copy.shape\n",
    "        \n",
    "        # Calculate the needed information for each node to get the yhat\n",
    "        for i in range(num_nodes):\n",
    "            with torch.no_grad():\n",
    "                h_u = Z_K[i,:] - H_copy[i,:]*self.Abar[i,i]\n",
    "            # Local update\n",
    "            self.node_list[i].receive_and_update(self.Abar[i,i], h_u, H[i], E)\n",
    "            \n",
    "        # Collect the updated local parameters and aggregate\n",
    "        with torch.no_grad():\n",
    "            for pname in self.cparam_names:\n",
    "                p = self.node_list[0].mlp.state_dict()[pname]\n",
    "                for i in range(1, self.num_nodes):\n",
    "                    p = p + self.node_list[i].mlp.state_dict()[pname]\n",
    "                p = p/self.num_nodes\n",
    "                self.central_params[pname] = p\n",
    "            \n",
    "            \n",
    "    def training(self, T, E, data=None):\n",
    "        \n",
    "        \n",
    "        accuracy = []\n",
    "        for t in range(T):\n",
    "            self.one_communication(E)\n",
    "            print (\"Communication:\", t+1)\n",
    "            if (data != None):\n",
    "                accuracy.append(self.training_accuracy(data, self.central_params))\n",
    "                \n",
    "        if (data != None):\n",
    "            plt.plot(np.arange(T)+1, accuracy)\n",
    "            return accuracy\n",
    "                \n",
    "            \n",
    "    def training_accuracy(self, graph_data, params):\n",
    "        X = graph_data.x\n",
    "        Y = graph_data.y\n",
    "        self.mlp.load_state_dict(params)\n",
    "        with torch.no_grad():\n",
    "                H = self.mlp(X)\n",
    "                Z_K = torch.matmul(self.Abar, H)\n",
    "                preds = torch.max(Z_K, dim=1)[1]\n",
    "                counts = (preds == Y).sum()\n",
    "        return counts.item()/self.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_network(data, A, num_classes, hidden_dim, learning_rate, K,\n",
    "                       output_dim=None, sigma=False):\n",
    "    \n",
    "    num_nodes, input_dim = data.x.shape\n",
    "    node_list = []\n",
    "    \n",
    "    for v in range(num_nodes):\n",
    "        \n",
    "        if (output_dim != None and sigma == True):\n",
    "            mlp = MLP(input_dim, hidden_dim, output_dim, sigma)\n",
    "            \n",
    "        else:\n",
    "            mlp = MLP(input_dim, hidden_dim)\n",
    "            \n",
    "        node_v = Node(data.x[v,:], data.y[v], mlp, learning_rate, v)\n",
    "        node_list.append(node_v)\n",
    "    \n",
    "    network = Central_Server(data.edge_index, node_list, A, K)\n",
    "    \n",
    "    network.testing_mlp(input_dim, hidden_dim, output_dim, sigma)\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communication: 1\n",
      "Communication: 2\n",
      "Communication: 3\n",
      "Communication: 4\n",
      "Communication: 5\n",
      "Communication: 6\n",
      "Communication: 7\n",
      "Communication: 8\n",
      "Communication: 9\n",
      "Communication: 10\n",
      "Communication: 11\n",
      "Communication: 12\n",
      "Communication: 13\n",
      "Communication: 14\n",
      "Communication: 15\n",
      "Communication: 16\n",
      "Communication: 17\n",
      "Communication: 18\n",
      "Communication: 19\n",
      "Communication: 20\n",
      "Communication: 21\n",
      "Communication: 22\n",
      "Communication: 23\n",
      "Communication: 24\n",
      "Communication: 25\n",
      "Communication: 26\n",
      "Communication: 27\n",
      "Communication: 28\n",
      "Communication: 29\n",
      "Communication: 30\n",
      "Communication: 31\n",
      "Communication: 32\n",
      "Communication: 33\n",
      "Communication: 34\n",
      "Communication: 35\n",
      "Communication: 36\n",
      "Communication: 37\n",
      "Communication: 38\n",
      "Communication: 39\n",
      "Communication: 40\n",
      "Communication: 41\n",
      "Communication: 42\n",
      "Communication: 43\n",
      "Communication: 44\n",
      "Communication: 45\n",
      "Communication: 46\n",
      "Communication: 47\n",
      "Communication: 48\n",
      "Communication: 49\n",
      "Communication: 50\n",
      "Communication: 51\n",
      "Communication: 52\n",
      "Communication: 53\n",
      "Communication: 54\n",
      "Communication: 55\n",
      "Communication: 56\n",
      "Communication: 57\n",
      "Communication: 58\n",
      "Communication: 59\n",
      "Communication: 60\n",
      "Communication: 61\n",
      "Communication: 62\n",
      "Communication: 63\n",
      "Communication: 64\n",
      "Communication: 65\n",
      "Communication: 66\n",
      "Communication: 67\n",
      "Communication: 68\n",
      "Communication: 69\n",
      "Communication: 70\n",
      "Communication: 71\n",
      "Communication: 72\n",
      "Communication: 73\n",
      "Communication: 74\n",
      "Communication: 75\n",
      "Communication: 76\n",
      "Communication: 77\n",
      "Communication: 78\n",
      "Communication: 79\n",
      "Communication: 80\n",
      "Communication: 81\n",
      "Communication: 82\n",
      "Communication: 83\n",
      "Communication: 84\n",
      "Communication: 85\n",
      "Communication: 86\n",
      "Communication: 87\n",
      "Communication: 88\n",
      "Communication: 89\n",
      "Communication: 90\n",
      "Communication: 91\n",
      "Communication: 92\n",
      "Communication: 93\n",
      "Communication: 94\n",
      "Communication: 95\n",
      "Communication: 96\n",
      "Communication: 97\n",
      "Communication: 98\n",
      "Communication: 99\n",
      "Communication: 100\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "data.edge_index = utils.remove_self_loops(data.edge_index)[0]\n",
    "data.edge_index = utils.add_remaining_self_loops(data.edge_index)[0]\n",
    "G = utils.to_networkx(data, to_undirected=True)\n",
    "A = torch.tensor(nx.linalg.graphmatrix.adjacency_matrix(G).todense()).type(torch.FloatTensor)\n",
    "D = nx.linalg.graphmatrix.adjacency_matrix(G).todense() + nx.linalg.laplacianmatrix.laplacian_matrix(G).todense()\n",
    "Dhalf = scipy.linalg.sqrtm(D)\n",
    "Dnhalf = torch.tensor(scipy.linalg.inv(Dhalf)).type(torch.FloatTensor)\n",
    "A = torch.matmul(torch.matmul(Dnhalf, A), Dnhalf)\n",
    "server = init_network(data, A, 7, 100, 1, 100, 7, True)\n",
    "accuracy = server.training(100, 1, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
